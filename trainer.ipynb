{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-05T19:41:03.044084Z",
     "start_time": "2025-03-05T19:40:45.074028Z"
    }
   },
   "source": [
    "import labeler\n",
    "!pip install torch torchaudio torchvision librosa matplotlib soundfile"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\r\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/81/b4/605ae4173aa37fb5aa14605d100ff31f4f5d49f617928c9f486bb3aaec08/torch-2.6.0-cp312-none-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached torch-2.6.0-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\r\n",
      "Collecting torchaudio\r\n",
      "  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/ac/4a/d71b932bda4171970bdf4997541b5c778daa0e2967ed5009d207fca86ded/torchaudio-2.6.0-cp312-cp312-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached torchaudio-2.6.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\r\n",
      "Collecting torchvision\r\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/6e/1b/28f527b22d5e8800184d0bc847f801ae92c7573a8c15979d92b7091c0751/torchvision-0.21.0-cp312-cp312-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached torchvision-0.21.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: librosa in ./.venv/lib/python3.12/site-packages (0.10.2.post1)\r\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.1)\r\n",
      "Requirement already satisfied: soundfile in ./.venv/lib/python3.12/site-packages (0.13.1)\r\n",
      "Collecting filelock (from torch)\r\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/89/ec/00d68c4ddfedfe64159999e5f8a98fb8442729a63e2077eb9dcd89623d27/filelock-3.17.0-py3-none-any.whl.metadata\r\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.12.2)\r\n",
      "Collecting networkx (from torch)\r\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl.metadata\r\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.5)\r\n",
      "Collecting fsspec (from torch)\r\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/e2/94/758680531a00d06e471ef649e4ec2ed6bf185356a7f9fbfbb7368a40bd49/fsspec-2025.2.0-py3-none-any.whl.metadata\r\n",
      "  Using cached fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (75.8.2)\r\n",
      "Collecting sympy==1.13.1 (from torch)\r\n",
      "  Obtaining dependency information for sympy==1.13.1 from https://files.pythonhosted.org/packages/b2/fe/81695a1aa331a842b582453b605175f419fe8540355886031328089d840a/sympy-1.13.1-py3-none-any.whl.metadata\r\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\r\n",
      "  Obtaining dependency information for mpmath<1.4,>=1.1.0 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\r\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from torchvision) (2.1.3)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.12/site-packages (from torchvision) (11.1.0)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./.venv/lib/python3.12/site-packages (from librosa) (3.0.1)\r\n",
      "Requirement already satisfied: scipy>=1.2.0 in ./.venv/lib/python3.12/site-packages (from librosa) (1.15.2)\r\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in ./.venv/lib/python3.12/site-packages (from librosa) (1.6.1)\r\n",
      "Requirement already satisfied: joblib>=0.14 in ./.venv/lib/python3.12/site-packages (from librosa) (1.4.2)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./.venv/lib/python3.12/site-packages (from librosa) (5.2.1)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in ./.venv/lib/python3.12/site-packages (from librosa) (0.61.0)\r\n",
      "Requirement already satisfied: pooch>=1.1 in ./.venv/lib/python3.12/site-packages (from librosa) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./.venv/lib/python3.12/site-packages (from librosa) (0.5.0.post1)\r\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./.venv/lib/python3.12/site-packages (from librosa) (0.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in ./.venv/lib/python3.12/site-packages (from librosa) (1.1.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.56.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (24.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in ./.venv/lib/python3.12/site-packages (from soundfile) (1.17.1)\r\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=1.0->soundfile) (2.22)\r\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./.venv/lib/python3.12/site-packages (from numba>=0.51.0->librosa) (0.44.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from pooch>=1.1->librosa) (4.3.6)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.venv/lib/python3.12/site-packages (from pooch>=1.1->librosa) (2.32.3)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\r\n",
      "Using cached torch-2.6.0-cp312-none-macosx_11_0_arm64.whl (66.5 MB)\r\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\r\n",
      "Using cached torchaudio-2.6.0-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\r\n",
      "Using cached torchvision-0.21.0-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\r\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\r\n",
      "Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)\r\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\r\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch, torchvision, torchaudio\r\n",
      "Successfully installed filelock-3.17.0 fsspec-2025.2.0 mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 torch-2.6.0 torchaudio-2.6.0 torchvision-0.21.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T19:41:29.855964Z",
     "start_time": "2025-03-05T19:41:24.645087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ],
   "id": "987f5383e3fb6e5b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class AudioDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset that:\n",
    "      - Recursively scans a directory for audio files (wav or npy).\n",
    "      - Parses labels from filename (basic approach).\n",
    "      - Loads audio, converts to a Mel-spectrogram.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir, sample_rate=44100, n_mels=64, transform=None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_mels = n_mels\n",
    "        self.transform = transform\n",
    "\n",
    "        # Collect all .wav or .npy files in data_dir\n",
    "        # wav_files = glob.glob(os.path.join(data_dir, \"*.wav\"))\n",
    "        npy_files = glob.glob(os.path.join(data_dir, \"*.npy\"))\n",
    "        self.audio_files = npy_files\n",
    "        self.audio_files.sort()\n",
    "\n",
    "        # In a real scenario, we have a separate label file or use a more robust approach\n",
    "        # For simplicity, we parse the label from the filename structure, e.g.:\n",
    "        #   \"good_coin_123456.wav\" -> \"good_coin\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.audio_files[idx]\n",
    "        filename = os.path.basename(file_path)\n",
    "\n",
    "        # Example label parsing:\n",
    "        # split on '_' and take first 1 or 2 tokens\n",
    "        # or parse \"good_coin\" until the next underscore\n",
    "        # do what's appropriate for your naming\n",
    "        label_str = filename.split(\"_\")[0]  # e.g. \"accept\", \"reject\"\n",
    "\n",
    "        # Convert label_str to a numeric class index\n",
    "        if \"accept\" in label_str:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "\n",
    "        # Load audio data\n",
    "        if file_path.endswith(\".wav\"):\n",
    "            # Load WAV\n",
    "            y, sr = librosa.load(file_path, sr=self.sample_rate, mono=True)\n",
    "        else:\n",
    "            # Load NPY\n",
    "            y = np.load(file_path)\n",
    "            sr = self.sample_rate  # assume consistent sample rate\n",
    "\n",
    "        # Convert to Mel-spectrogram\n",
    "        # shape -> (n_mels, time)\n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=y, sr=sr, n_mels=self.n_mels, fmax=sr//2\n",
    "        )\n",
    "        # Convert to decibels\n",
    "        mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "        # Optional: apply transform / augmentation\n",
    "        if self.transform:\n",
    "            mel_db = self.transform(mel_db)\n",
    "\n",
    "        # Convert to float tensor\n",
    "        mel_tensor = torch.tensor(mel_db, dtype=torch.float)\n",
    "\n",
    "        # (n_mels, time) -> (1, n_mels, time) to match CNN [batch, channel, H, W]\n",
    "        mel_tensor = mel_tensor.unsqueeze(0)\n",
    "\n",
    "        return mel_tensor, label"
   ],
   "id": "2245d2c0fa5bb1a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ALL_TAGS = [\"accept\", \"reject\"]\n",
    "ALL_TAGS.extend(labeler.AVAILABLE_TAGS)  # gets the rest of tags, coin, ring, foil, silver, gold, ringpull,...\n",
    "tag2idx = {tag: idx for idx, tag in enumerate(ALL_TAGS)}\n",
    "\n",
    "\n",
    "def parse_tags_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Example filename: \"accept_coin_silver_123abc.wav\"\n",
    "    We'll parse out [\"accept\", \"coin\", \"silver\", \"123abc\"] from the base,\n",
    "    and set those tags to 1 in a multi-hot label vector.\n",
    "    \"\"\"\n",
    "    base, _ = os.path.splitext(filename)  # e.g. \"accept_coin_silver_123abc\"\n",
    "    parts = base.split(\"_\")  # [\"accept\", \"coin\", \"silver\", \"123abc\"]\n",
    "\n",
    "    # Initialize multi-hot vector (all zeros)\n",
    "    label_vec = [0] * len(ALL_TAGS)\n",
    "\n",
    "    # For each part, if it's a recognized tag, set to 1\n",
    "    for p in parts:\n",
    "        if p in tag2idx:\n",
    "            label_vec[tag2idx[p]] = 1\n",
    "\n",
    "    return label_vec"
   ],
   "id": "16dfd73eac9c485e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
